{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Short intro to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keras is a `python` library which implements a wrapper around well-known deep learning packages. It runs with either `theano` or `tensorflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The basic idea\n",
    "\n",
    "* You define **how your network looks like**\n",
    "* You **compile** the graph\n",
    "* You **train and evaluate** your model (similar to `sklearn` with `fit` and `predict`/`evaluate`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keras implements two main approaches:\n",
    "    \n",
    "    * the Sequential model\n",
    "    * the functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main type of model is the **Sequential** model, a linear stack of layers.\n",
    "\n",
    "I recommend to start with the Sequential model, but as soon as your model gets more involved it might make sense to use the functional API instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sequential means that it takes a list of layers. You can add one layer at a time to the model. Here is a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "vocab_size=100\n",
    "model.add(Dense(units=64, input_dim=vocab_size))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the first layer you need to specify its dimensions, the remaining layers will infer the size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Changes to Keras 2:\n",
    "\n",
    "output_dim => units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternative, equivalent formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "vocab_size=100  \n",
    "model.add(Dense(units=64, input_dim=vocab_size, activation=\"relu\")) #alternative\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then you can compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy']) # many optimizers available, on small datasets 'adam' might work well\n",
    "\n",
    "## need X_train, y_train\n",
    "# model.fit(X_train, y_train,\n",
    "#          nb_epoch=args.iters,\n",
    "#          batch_size=100, validation_data=(X_dev, y_dev))\n",
    "\n",
    "## and either 'predict' or 'evaluate' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A complicated LSTM model is easly created (but we will see that back later): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dropout\n",
    "\n",
    "num_labels=2\n",
    "vocabulary_size=10000\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=128, input_dim=vocabulary_size, input_length=100))\n",
    "model.add(LSTM(units=64, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the functional API each layer is a function and can be applied to another layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten\n",
    "\n",
    "# input: a sequence  of 5 integers, each representing a word (index between 0 and vocab_size).\n",
    "main_input = Input(shape=(5,), dtype='int32', name='main_input')\n",
    "\n",
    "# now the embedding layer will encode the input sequence\n",
    "# into a sequence of dense 128-dimensional vectors.\n",
    "embeds = Embedding(output_dim=128, input_dim=vocabulary_size, input_length=5)(main_input)\n",
    "flatten = Flatten()(embeds) # we flatten it as Dense expects a 2D input\n",
    "dense = Dense(64, activation='tanh')(flatten)\n",
    "\n",
    "# finally the softmax (logistic) output layer\n",
    "main_loss = Dense(num_labels, activation='softmax', name='main_output')(dense)\n",
    "\n",
    "# the model is specified by connecting input and output\n",
    "model = Model(input=[main_input], output=[main_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the functional API you can create a lot advanced models relatively quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* http://keras.io/#getting-started-30-seconds-to-keras\n",
    "* http://keras.io/getting-started/sequential-model-guide/\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
