{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* Convolution-and-pooling architectures (LeCun & Bengio, 1995) evolved in the neural\n",
    "networks computer vision community\n",
    "* Computer Vision (CV): image classification, caption generation, photo tagging, self-driving cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* invariance in data:\n",
    "  * image of kitten in different positions in image \n",
    "  * want to find object regardless of its position in the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convolutional neural networks (CNNs or convnets) are a  specialized kind of neural network **for processing data that has a known, grid-like topology** [[1](http://www.deeplearningbook.org/contents/convnets.html)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Image data**: can be thought of a 2-dimensional (grid) \n",
    "* **Text data**: 1-d (sequence) / time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNNs (or 'convnets')\n",
    "\n",
    "* are Neural Networks that works on variable length inputs\n",
    "* the name **convolution** comes from the fact that this model uses a mathematical operation called *convolution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* in fact, the two basic operations of a CNN are **convolution** and **pooling** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What are convolutions?\n",
    "\n",
    "* \"identifying indicative local predictors\" (Goldberg, 2015)\n",
    "* a grid that goes over the input\n",
    "* a *convolution* is an operation (of two functions) where one is the **input**, the other is a kernel that acts like a **filter** on the input producing an output\n",
    "* we are sliding the *kernel* over the input; it computes a windowed averaged representation of the input vector\n",
    "\n",
    "#### Example of a 2d convolution:\n",
    "\n",
    "An image is a 2d input, the following illustrates a convolution over this 2d input:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz44.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz45.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is an animation (src: Convolution with 3×3 Filter). Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)\n",
    "<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [[2](http://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf)]\n",
    "\n",
    "* Our images and kernels are 2D functions (aka matrices).\n",
    "* We slide the kernel over each pixel of the image, multiply the\n",
    "corresponding entries of the input and kernel, and add them up (convolution + average pooling).\n",
    "\n",
    "<img src=\"pics/cnn-cv1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/cnn-cv2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/cnn-cv3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminology:\n",
    "\n",
    "* convolution\n",
    "* filter\n",
    "* stride\n",
    "* pooling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pooling\n",
    "\n",
    "Max pooling in CNN. Source: http://cs231n.github.io/convolutional-networks/#pool\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png\" width=600>\n",
    "\n",
    "stride: 2 pixels (jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutions for text\n",
    "\n",
    "* CNNs were introduced in NLP by Collobert et al. (2011) and later by Kim (2014) and Kalchbrenner et al. (2014)\n",
    "* the intention is to let the network focus on the most important \"features\" in the sentence, regardless of their location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main idea behind a convolution and pooling architecture for language tasks is to apply\n",
    "a non-linear (learned) function over each instantiation of a $k$-word sliding window over\n",
    "the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/cnn-goldberg.png\">\n",
    "Illustration from Goldberg (2015) chapter 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    \n",
    "* **convolution**: a $k$-word sliding window is input for a function (**filter**) that transforms the window of k words into a $d$ dimensional vector (where each dimension is called a **channel**)\n",
    "* **pooling**: then, a pooling operation combines vectors from different windows into a $d$-dim vector by taking the **max** (max-pooling) or **average** value observed in each of the channels (max pooling/average pooling)\n",
    "\n",
    " The resulting vector is a representation for the entire sentence in which each dimension represents the most salient features for some prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In more detail, including mathematical formulation:\n",
    "\n",
    "<img src=\"pics/cnn-illustration.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The gradients that are propagated\n",
    "back from the network’s loss during the training process are used to tune the parameters\n",
    "of the filter function to highlight the aspects of the data that are important for the task\n",
    "the network is trained for. Intuitively, when the sliding window is run over a sequence, the\n",
    "filter function learns to identify informative k-grams. (Goldberg, 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also do different convolutions on different parts of the sentence/document (see section 9.2, Goldberg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are convnets?\n",
    "\n",
    "* several layers of convolutions (with activation functions) and pooling\n",
    "\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kim (2014)\n",
    "\n",
    "* apply several convoluational layers in parallel\n",
    "<img src=\"pics/kim2014.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=128, input_dim=10000, input_length=5))\n",
    "\n",
    "num_filters = 250\n",
    "conv_length = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters=num_filters,  # Number of convolution kernels to use (dimensionality of the output).\n",
    "                 kernel_size=conv_length, #  The extension (spatial or temporal) of each filter.\n",
    "                 padding='valid',  #valid: don't go off edge; same: use padding before applying filter\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "\n",
    "# max pooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* [Goldberg's primer chapter 9](arxiv.org/abs/1510.00726)\n",
    "* [WildML: CNNs for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/#more-348)\n",
    "* [Cornell course notes](http://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
